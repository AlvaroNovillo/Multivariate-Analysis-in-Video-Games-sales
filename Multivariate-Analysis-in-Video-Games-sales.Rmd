---
output: 
  stevetemplates::article:
    fig_caption: true
    includes:
      in_header: "wrap-code.tex"
bibliography: master.bib
biblio-style: apsr
title: "Multivariate Analysis in Video Games sales"
thanks: "Replication files are available on the author's Github account (https://github.com/AlvaroNovillo). **Current version**: `r format(Sys.time(), '%B %d, %Y')`; **Corresponding author**: alvanovi@ucm.es."
author:
- name: √Ålvaro Novillo
  affiliation: Universidad Carlos III
- name: Paolo Salvatore Lodato Olano
  affiliation: Universidad Carlos III
abstract: "In this article, we perform several dimensionality reduction techniques and clustering algorithms on a video game sales dataset available on Kaggle (https://www.kaggle.com/datasets/gregorut/videogamesales/data). Specifically, we use Principal Component Analysis (PCA) and Multidimensional Scaling (MDS) to reduce the dimensionality of the dataset. The article discusses the advantages and limitations of each technique and provides insights into the video game market based on the analysis."
keywords: "PCA, Videogames, Sales"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
# spacing: double
endnote: no
---

```{r setup, include=FALSE}
library(kableExtra)
library(ggplot2)
options(kableExtra.latex.load_packages = TRUE)
knitr::opts_chunk$set(cache=TRUE,
                      message=FALSE, warning=FALSE,
                      fig.path='figs/',
                      cache.path = '_cache/',
                      fig.process = function(x) {
                      x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
                      if (file.rename(x, x2)) x2 else x
                      })
```

## About the dataset

The dataset under consideration contains information on video games with sales greater than 100,000 copies between 1980 and 2016. The dataset includes 11,493 unique game sales, detailing the name, year of release, genre, platform, and sales figures across numerous regions.

The dataset contains the following fields:

-   **Rank** - Ranked by overall sales
-   **Name** - Name of each videogame
-   **Platform** - The games platform
-   **Year** - Year of Release
-   **Genre** - Genre of Game
-   **Publisher** - Publisher of Game
-   **NA_Sales** - Sales in NA (per Million)
-   **EU_Sales** - Sales in EU (per Million)
-   **JP_Sales** - Sales in JP (per Million)
-   **Other_Sales** - Sales in ROW[^1] (per Million)
-   **Global_Sales** - Total worldwide sales (per Million)

[^1]: Net Sales (ROW) means the gross amount billed or invoiced on sales by Company and its Affiliates and Sublicensees of Licensed Products, less the following: (a) customary trade, quantity, or cash discounts and commissions to non-affiliated brokers or agents to the extent actually allowed and taken; (b) amounts repaid or credited by reason of rejection or return; (c) to the extent separately stated on purchase orders, invoices, or other documents of sale, any taxes or other governmental charges levied on the production, sale, transportation, delivery, or use of a Licensed Product which is paid by or on behalf of Company; (d) outbound transportation costs prepaid or allowed and costs of insurance in transit; and (e) allowance for bad debt that is customary and reasonable for the industry and in accordance with generally accepted accounting principles. [@lawinsider]

## Data Preprocessing

The dataset contains 11 variables, including quantitative variables like sales figures across various regions (NA_Sales, EU_Sales, JP_Sales, Other_Sales, and Global_Sales), the release year, and the rank of the game based on overall sales. Additionally, it includes multi-state categorical variables like the genre, platform, and publisher of the game. To conform with the desired format, which requires at least two binary variables, we will filter out the video games of recent years and focus on titles that we are already acquainted with. Moreover, we will limit our research to two primary platforms, namely, Xbox One and PS4.

```{r preprocessing, echo=FALSE}
df = read.csv("vgsales.csv")

# Filter for games in 2015 and 2016, and on the PS4 or PC platform
filtered_df <- df[df$Year %in% c(2015, 2016) & df$Platform %in% c("PS4", "XOne"), ]
head(filtered_df) %>%
  kbl(booktabs = T, caption = "Top five videogames, according to the sales ranking, that we are going to work with") %>%
  kable_styling(latex_options = c("striped", "scale_down","hold_position"), position = "center")

```

In Table 1. the top five selling games for 2015 and 2016, in PS4 ans Xbox One are shown. As we can see, the first one, which is Call Of Duty: Black Ops 3 is among the top 50 best selling games of the dataset (in PS4).

Examining the distribution of the filtered games rank, as seen in Fig. 1, considering its skewness, it can be confirmed that the vast majority of games released during this time period did not have a significant impact on the industry. In fact, the average ranking of games within our dataset stands at 9373.

```{r rank_distrib,echo= FALSE,fig.cap = "Distribution of the log-transformed Rank values. The red dashed line represents the median of the distribution"}
# Create a histogram
# Calculate the median of the log-transformed Rank
median_rank <- median(log(filtered_df$Rank))

# Create a histogram with median line and text
ggplot(data = filtered_df, aes(y = log(Rank))) +
  geom_histogram(fill = "skyblue", color = "black") +
  geom_hline(yintercept = median_rank, linetype = "dashed", color = "red") +
  geom_text(aes(x = 70, y = median_rank - 0.1 ,label = round(exp(median_rank), 2)),
            vjust = -1, hjust = -0.2, color = "red") +
  labs(y = "log(Rank)") +
  theme_minimal()
```

Figs. 2 and 3 allow us to explore the basic features of our dataset, informing us of the amount of games from each platform, and the amount of games of each genre. In our dataset, the mayority of the sold games are from PS4, and the most popular genre is Action, followed by Sports, Role-Playing and Shooter

```{r num_games, echo=FALSE, fig.cap= "Number of games of each platform inside the dataset"}
# Load the ggplot2 library if not already loaded
library(ggplot2)

# Create a barplot of the number of games per platform with custom colors
platform_counts <- table(filtered_df$Platform)
platform_counts_df <- data.frame(Platform = names(platform_counts), Count = as.vector(platform_counts))

# Define custom colors for XOne and PS4
custom_colors <- c("XOne" = "green", "PS4" = "blue")

ggplot(data = platform_counts_df, aes(x = reorder(Platform, -Count), y = Count, fill = Platform)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = custom_colors) +  # Apply custom colors
  labs(x = "Platform",
       y = "Number of Games") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r num_genres, echo=FALSE, fig.cap= "Barplot of the amount of games of each genre"}
# Create a barplot of the number of games per platform with custom colors
genre_counts <- table(filtered_df$Genre)
genre_counts_df <- data.frame(Genre = names(genre_counts), Count = as.vector(genre_counts))

ggplot(data = genre_counts_df, aes(x = reorder(Genre, -Count), y = Count, fill = Genre)) +
  geom_bar(stat = "identity") +
  labs(x = "Genre",
       y = "Number of Games") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

From the previous plot we can see the Rank variable is right skewed. For positive skewness we can apply a log transformation^[Since the variables referring to the sales in our dataset presents zeros, we have applied Box-Cox technique (See @box) to identify the appropriate transformation for our case (obtaining $\lambda \approx 0$), leading to the application of $log(x + \epsilon)$ transformation, being $\epsilon > 0$ an arbitrary small constant.], which would help to normalize the distribution of the variables. Many statistical methods, including linear regression and analysis of variance, assume that the residuals are normally distributed. Normalizing our data would also be useful to help achieve zero mean and unit variance. In Fig. 4, we can visualize these transformations performed on the sales variables.

```{r box_transform, echo=FALSE, fig.cap= "Boxplots of the different transformations applyied to the sales data. From left to right, the original data, the log-transformed data and the log transformed and scaled data"}
par(mfrow = c(1, 3))
data <- filtered_df[sapply(df,is.numeric)][,2:4]

# Create boxplots
boxplot(data, main = "Original Data")
boxplot(log(data + 0.001) , main = "Log Transformed Data")
boxplot(scale(log(data + 0.001)), main = "Log & Scaled Data")

data <- as.data.frame(scale(log(data + 0.001)))

```

Since the ranking is solely determined by overall sales figures, it is worthwhile investigating whether the top-selling game in certain regions differs from that of others. Our expectation is that the best-selling games in Japan will differ from those sold in the West. To do such analysis, we will start by computing the *correlation matrix* of the sales in the different regions. 

```{r, echo=FALSE}

covariance <- cor(data)
round(covariance,3) %>%
  kbl(booktabs = T, caption = "Covariance matrix of sales") %>%
  kable_styling(latex_options = c("striped","hold_position"), position = "center")

```

The *correlation matrix* can be computed as follows: $\text{Cor}(X, Y) = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y}$, where $\text{Cov}(X, Y)$ is the covariance between variables $X$ and $Y$, and $\sigma_X$ and $\sigma_Y$ are their respective standard deviations. The correlation matrix provides a comprehensive view of the linear relationships between variables in a dataset. It is useful for identifying patterns, understanding dependencies, and detecting multicollinearity in statistical analyses.

Doing so (Table 2), we can see that the correlation between the sales in Japan and the Western market is 0.044, with an even lower correlation of 0.01 with the American market, as illustrated in Fig. 5. This raises compelling questions about the underlying factors that contribute to these correlations. It is clear that several key factors highlight the significant differences between the Oriental and Western video game industries, leading to this low correlation. 

First and foremost, the contrast in gaming preferences between regions plays a key role. As seen in the intercorrelation measurements, there is some correlation in the sales in Europe and NA. In the West, specifically in North America, action and shooter games are incredibly popular. However, the Japanese market favours Role Playing Games (RPGs), which differs greatly from the Western market. As a result of these diverging gaming genres, differing sales patterns naturally occur, ultimately contributing to the observed low correlation.

The marketing and localization strategies employed in the Japanese video game industry hold immense importance. Many Japanese games prioritize the local market, leading to gameplay and cultural elements that might not strongly resonate with Western or North American audiences. Consequently, these games might struggle to achieve success beyond their intended Eastern audience, resulting in a larger sales gap and weaker association with these regions. In contrast, sales in North America and Europe tend to be more closely linked due to their shared Western cultures and comparable marketing approaches. Conversely, Japan represents a distinct market, with its citizens' preferences significantly differing from those of Western cultures.

It is also worth noting that given the nature of the variables, they all present a positive correlation. To ensure the low *intercorrelation* between our sales data, we have computed different correlation measures^[The computed metrics are the ones that have been sugested in class. See @aurea1], presented in Table 3. 


```{r, echo=FALSE}
intercorrelations <- function(X) {
  # Get the dimensions of the matrix X
  dim_X <- dim(X)
  n <- dim_X[1]
  p <- dim_X[2]
  
  # Compute the correlation matrix R
  R <- cor(X)
  
  # Initialize the output vector q
  q <- rep(0, 6)
  
  # Compute eigenvalues of R
  lambda <- eigen(R)$values
  
  # Compute diagonal elements of the inverse of R
  rjj <- diag(solve(R))
  
  # Calculate intercorrelations measures
  q[1] <- (1 - min(lambda) / max(lambda))^(p + 2)
  q[2] <- 1 - p / sum(1 / lambda)
  q[3] <- 1 - sqrt(det(R))
  q[4] <- (max(lambda) / p)^(3/2)
  q[5] <- (1 - min(lambda) / p)^5
  q[6] <- sum((1 - 1/rjj) / p)
  
  # Return the result vector q
  return(q)
}

q <- intercorrelations(data)
q <- t(as.data.frame(q))
colnames(q) <- c('q1','q2','q3','q4','q5','q6')
round(q,3) %>%
  kbl(booktabs = T, caption = "Correlation measurements of the sales in the different regions") %>%
  kable_styling(latex_options = c("striped","hold_position"), position = "center")
```

As noted earlier when examining the correlation between pairs of markets, the intercorrelation between the three markets is low because of the aforementioned socio-cultural factors.

```{r, echo=FALSE}
library(GGally)
library(gridExtra)
library(cowplot)
library(ggpubr)

plot.mpg <- ggpairs(data, 
                    lower = list(mapping = aes(color = filtered_df$Genre)),
                    diag = list(continuous = "barDiag")) +    
    scale_fill_manual(values=c("Shooter" ="#3366FF" ,      # Assigning colors to each category
                                "Sports" = "#FF5733", 
                                "Role-Playing" = "#FF33FF", 
                                "Action" = "#FFCC33", 
                                "Fighting" = "#33FF57", 
                                "Racing" = "#FF3366", 
                                "Adventure" = "#33FFFF",
                                "Platform" = "#9966FF",
                                "Misc" = "#999999",
                                "Simulation" = "#FF9933",
                                "Strategy" = "#33FFCC",
                                "Puzzle" = "#FF33CC")) +
    scale_colour_manual(values=c("Shooter" = "#FF5733",      # Assigning colors to each category
                                "Sports" = "#3366FF", 
                                "Role-Playing" = "#FF33FF", 
                                "Action" = "#FFCC33", 
                                "Fighting" = "#33FF57", 
                                "Racing" = "#FF3366", 
                                "Adventure" = "#33FFFF",
                                "Platform" = "#9966FF",
                                "Misc" = "#999999",
                                "Simulation" = "#FF9933",
                                "Strategy" = "#33FFCC",
                                "Puzzle" = "#FF33CC"))

# Save the ggpairs plot as a PDF
pdf("ggpairs_plot.pdf")
print(plot.mpg)
# Convert the saved ggpairs plot to a grob
saved_plot <- grid::grid.grab()


# Generate the legend separately
legend_plot <- ggplot(data, aes(x = 1, y = 1, color = filtered_df$Genre)) +
  geom_point(size = 5) +
  scale_color_manual(name = "Genre",  # Legend title
                     values = c("Shooter" = "#3366FF",      # Assigning colors to each category
                                "Sports" = "#FF5733", 
                                "Role-Playing" = "#FF33FF", 
                                "Action" = "#FFCC33", 
                                "Fighting" = "#33FF57", 
                                "Racing" = "#FF3366", 
                                "Adventure" = "#33FFFF",
                                "Platform" = "#9966FF",
                                "Misc" = "#999999",
                                "Simulation" = "#FF9933",
                                "Strategy" = "#33FFCC",
                                "Puzzle" = "#FF33CC"))  +
  theme_void() +
  theme(legend.position = "right")


# Extract the legend. Returns a gtable
leg <- get_legend(legend_plot)

# Convert to a ggplot and print
# Arrange the plots side by side
par(mfrow = c(1, 2))
plot = grid.arrange(saved_plot, as_ggplot(leg), ncol = 2,widths = c(0.8, 0.2))
```

```{r sales_pairs,echo=FALSE,fig.cap= "Correlation Plot of Video Game Sales in Different Regions"}
as_ggplot(plot)
```

To delve deeper into the differences in the market, Table 4 presents a comprehensive analysis of the percentage distribution of sales across the top three genres within diverse regions under investigation. It is evident from the table that the Role-Playing Games (RPGs) enjoys significantly greater popularity in Japan as compared to North America and Europe. Strikingly, our research reveals that Action games emerge as the most prevalent genre in Japan, accounting for a substantial portion of the region's total sales, encompassing 35.28% of the market share. This results can also be found in Fig. 5, where we can see almost all Role-playing and Action games are above the diagonal line (y = x) in the last row plots (where Japanese sales is the y axis), indicating the higher popularity of this genres in the Japanese market  

```{r top_genre,echo=FALSE}
library(dplyr)

# Group and summarize the data by genre for each region
genre_sales <- filtered_df %>%
  group_by(Genre) %>%
  summarise(
    Total_NA_Sales = sum(NA_Sales),
    Total_EU_Sales = sum(EU_Sales),
    Total_JP_Sales = sum(JP_Sales)
  ) %>%
  ungroup()

# Calculate the total sales for each region
total_sales <- genre_sales %>%
  summarise(
    Total_NA_Sales = sum(Total_NA_Sales),
    Total_EU_Sales = sum(Total_EU_Sales),
    Total_JP_Sales = sum(Total_JP_Sales)
  )

# Calculate the percentage of total sales for each genre in each region
genre_sales <- genre_sales %>%
  mutate(
    Percentage_NA_Sales = round((Total_NA_Sales / total_sales$Total_NA_Sales) * 100,2),
    Percentage_EU_Sales = round((Total_EU_Sales / total_sales$Total_EU_Sales) * 100,2),
    Percentage_JP_Sales = round((Total_JP_Sales / total_sales$Total_JP_Sales) * 100,2)
  )

# Select the top 3 genres for each region
top_genres <- genre_sales %>%
  mutate(
    Rank_NA = row_number(desc(Percentage_NA_Sales)),
    Rank_EU = row_number(desc(Percentage_EU_Sales)),
    Rank_JP = row_number(desc(Percentage_JP_Sales))
  ) %>%
  filter(Rank_NA <= 2 | Rank_EU <= 2 | Rank_JP <= 2) %>%
  select(Genre, Percentage_NA_Sales, Percentage_EU_Sales, Percentage_JP_Sales)



top_genres %>%
  kbl(booktabs = T, caption = "Percentage distribution of sales for the top three genres in different regions") %>%
  kable_styling(latex_options = c("striped","hold_position"), position = "center")
```

## Principal Component Analysis (PCA)
After an initial exploration and necesary preprocessing of the dataset, we are now ready to conduct Principal Component Analysis (PCA) to reduce the problem's dimensionality.

Principal Component Analysis (PCA) constitutes a vital stage in our data analysis pipeline for several reasons. It enables us to reduce the dimensionality of our dataset by transforming the initial variables into a set of independent principal components, which capture the essential information with fewer variables. This reduction becomes particularly valuable when dealing with datasets of high dimensionality, as it allows for more manageable and comprehensible analyses. 

In our Principal Component Analysis, all avaliable sales variables will be taken into account. Thus, beside from the sales of the three principal regions at study, we will also consider the Sales in ROW^[See @lawinsider], and the Global sales (per Million)

```{r, echo=FALSE}
data <- scale(log(filtered_df[sapply(filtered_df,is.numeric)][2:6] + 0.001))

# Perform PCA
pca_result <- prcomp(data, scale = TRUE)

# View the summary of the PCA
round(summary(pca_result)$importance,3)  %>%
  kbl(booktabs = T, caption = "Summary of PCA") %>%
  kable_styling(latex_options = c("striped","hold_position"), position = "center")
```

As seen by the results (Table 5), $90.8\%$ of the total variability in the dataset has been explained by the two first components. Thus, these two variables can accurately represent the data. By using the package ${\tt factoextra}$ we can create a Scree plot (Fig. 6) that visualizes our decision on the number of components or factors retained in the analysis.

```{r scree, echo=FALSE, fig.cap = "Scree plot visualizing the number of components retained in the analysis. The red dashed line represents the cutoff selected "}
library(factoextra)
# Plotting PCA eigenvalues
plot <- fviz_eig(pca_result, addlabels = TRUE, ylim = c(0, 75), x = "Principal Components", y = "% of Explained Variance", top = 2, linetype = "dashed", geom = c("line"))

# Adding a horizontal line at y = 20.6
plot + geom_hline(yintercept = 20.6, linetype = "dashed", color = "red")

```

By examining the eigenvector that corresponds to the chosen variables, in this instance, the two highest eigenvalues' eigenvectors, we can provide an interpretation and significance to the selected variables.

```{r, echo=FALSE}
round(pca_result $rotation[, 1:2],2)  %>%
  kbl(booktabs = T, caption = "Variables contribution to the first two principal components") %>%
  kable_styling(latex_options = c("striped","hold_position"), position = "center")

```

The first principal component **PC1** seems to be influenced by each variable, having higher (negative) loadings for NA_Sales, EU_Sales, Other_Sales, and Global_Sales. This component highlights that these five criteria simultaneously fluctuate. Thus, if sales in a particular region increase, they tend to increase in the other regions, thereby increasing the Global Sales and Sales in the ROW. Sales in Japan also increase, but at a lower rate, due to the previously mentioned low correlation of the Japanese market with respect to the others. It can be understood as a measure of the total amount of sales

The second principal component **PC2** seems to represent a pattern primarily related to sales in Japan, distinguishing it from sales in other regions.

```{r pcaplot, echo=FALSE, fig.cap = "Principal Component Analysis (PCA) plot displaying the top selling game genres' distribution with respect to the two principal components. Points in yellow corresponds to Action games, those in pink to Role-Playing games, those in blue to Shooters, and the rest of the genres are visualized in grey."}


# Create a custom color palette
selected_colors <- c("Action" = "#FFCC33", "Role-Playing" = "#FF33FF", "Shooter" = "#3366FF")
other_color <- "grey"  # Color for the rest of the points

# Assign colors based on genres
colors <- ifelse(filtered_df$Genre %in% names(selected_colors),
                 selected_colors[as.character(filtered_df$Genre)],
                 other_color)

# Create a custom legend labels
legend_labels <- c("Others","Action", "Role-Playing", "Shooter")

# Create factors for the legend alignment
legend_factors <- factor(ifelse(filtered_df$Genre %in% names(selected_colors),
                               as.character(filtered_df$Genre),
                               "Others"),
                         levels = c("Others","Action", "Role-Playing", "Shooter" ))

# Visualize PCA with customized colors
fviz_pca_ind(pca_result,
             geom.ind = "point", # Show points only (not "text")
             col.ind = colors,   # Use customized colors
             addEllipses = TRUE, # Concentration ellipses
             palette = c(other_color, unique(selected_colors)),
             legend.title = "Genres",
             addLegend = TRUE,
             legend.labels = legend_labels,
             legend.key = list(space = "top", columns = 2), # Adjust legend appearance
             habillage = legend_factors # Use legend factors for alignment
)

```

Fig. 7 presents the principal components analysis of leading game genres. The games situated towards the left in the plot are indicative of the highest sales volumes, while those positioned towards the top mainly pertain to games predominantly sold in Japan. Shooter games (illustrated as blue crosses) are the most widely sold games worldwide, with some examples proving particularly profitable in the Japanese market, based by the points located in the top-left quadrant. As previously highlighted, certain action games (represented as yellow triangles) and role-playing games (denoted by pink squares) have a predominant presence in the Japanese market, with some exclusively marketed within this region (located notably in the top-right quadrant of the plot).

To conclude the PCA analysis, we can determine how much each variable is represented in a given component. To do so, we will implement the *square cosine* technique. Mathematically, the Cos2 for a variable or category in a given component is calculated as the squared cosine of the variable's/category's coordinates on that component.

The Cos2 values range between 0 and 1, where:

-   A low Cos2 value indicates that the variable/category is not well represented by the component.
-   A high Cos2 value signifies a strong representation of the variable/category on the component.

```{r repre, echo=FALSE, fig.cap = "Visualization of the quality of representation (Cos2) of rows/columns from the results of Principal Component Analysis (PCA). The color gradient represents the strength of representation, with black indicating low representation, orange indicating moderate representation, and red indicating high representation."}
fviz_pca_var(pca_result, col.var = "cos2",
            repel = TRUE, midpoint=0.5) +
  scale_color_gradient(limits = c(0.7, 1), low = "black", high = "#FF3366" )

```

Fig. 8 combines a biplot of the attributes with the computed cos2 score, from which we can extract that all variables that we considered when doing PCA are strongly represented in both of the principal components selected.

## Cluster analysis

After the initial exploratory data analysis, and performing Principal Component Analysis, we could delve deeper in our analysis including *cluster analysis*.

For cluster analysis, there are various methods you can apply to group similar instances together. Common techniques include K-means clustering, hierarchical clustering, and density-based clustering like DBSCAN. In our case, it is convenient to apply *K-means clustering* given the easy application of the algorithm, and the scaling and data pre-processing applied.

K-means clustering is an unsupervised machine learning algorithm that aims to partition $n$ data points into $\mathrm{k}$ clusters. The algorithm works by minimizing the sum of squared distances between the data points and their respective cluster centroids. 

The process involves the following steps:

-   1. Randomly select k data points as the initial cluster centroids.
-   2. Assign each data point $x_i$ to the nearest cluster centroid $\mu_j$ based on the Euclidean distance.
$$
d\left(x_i, \mu_j\right)=\sqrt{\sum_{n=1}^N\left(x_{i, n}-\mu_{j, n}\right)^2}
$$
where $N$ is the number of dimensions/features 1 .
-   3. The objective of K-means is to minimize the sum of squared distances within each cluster, which can be expressed as:
$$
WSS=\sum_{j=1}^k \sum_{x_i \in S_j}\left\|x_i-\mu_j\right\|^2
$$
where $S_j$ is the set of data points in cluster $j, \mu_j$ is the centroid of cluster $j$, and $k$ is the total number of clusters 1 .
-   4. The cluster centroids are updated by taking the mean of all data points assigned to that cluster:
$$
\mu_j=\frac{1}{\left|S_j\right|} \sum_{x_i \in S_j} x_i
$$
where $\left|S_j\right|$ is the number of data points in cluster $j$.

To select the number of clusters, we will use the *elbow* method, which consists of running the algorithm with a varying k and calculating a cost function for each run. Then the cost values are plotted against k values and we choose k at the turning point (called "elbow").

This algorithm can be applied in R using the *cluster* library as follows:
```{r kmeans}
library(cluster)

# Initialize empty vector to store within-cluster sum of squares
wss <- vector()

# Vary the number of clusters from 1 to 10 and compute the total within-cluster sum of squares
for (i in 1:10) {
  kmeans_model <- kmeans(data, centers = i, nstart = 10)
  wss[i] <- kmeans_model$tot.withinss
}
```   

Fig. 9 contains the elbow plot of the model created above. Given the results, we consider that using $K = 3$ clusters will be the best option to faciliate the interpretation of the results. 

```{r, echo=FALSE, fig.cap="Elbow plot for the K-means clustering algorithm "}
# Plot the elbow method to determine the optimal number of clusters
plot(1:10, wss, type = "b", xlab = "Number of Clusters", ylab = "Within-Cluster Sum of Squares (WSS)")

```

Fig. 10 visualizes the clusters found with respect with the previously found Principal Components.

```{r PCAclust, echo=FALSE,fig.cap= "Visualization of the clusters with respect to the Principal Components. Points with a higher size corresponds to the cluster centers of each group "}
library(factoextra)
num_clusters <- 3

# Apply K-means clustering
kmeans_model <- kmeans(data, centers = num_clusters, nstart = 10)

# Extract cluster assignments for each instance
cluster_assignments <- kmeans_model$cluster
cluster_assignments <- as.numeric(cluster_assignments)

# Plot PCA with clusters
library(factoextra)

# Plot PCA with clusters and centroids
fviz_pca_ind(pca_result,
             geom.ind = "point", # Show points only (not "text")
             col.ind = kmeans_model$cluster, # Color by cluster assignments
             addEllipses = TRUE, # Concentration ellipses
             legend.title = "Clusters",
             habillage = as.factor(kmeans_model$cluster), # Use cluster assignments
             geom.centroid = TRUE, # Add centroids
             pointsize = 2 # Set size of points
)



```

Based on Fig. 10,  we can derive an interpretation for the clusters found. The cluster labelled as 1, represents games with high or moderate sales volume and predominantly sold outside Japan (with some exceptions that seem to be popular in the Orient). The second cluster (2) includes games with the highest sales volume in Japan, with some exceptions regarding games with the highest sales volume in the West. Finally, the third (3) cluster contains the games with the lowest sales in our data set, both in Japan and in the West.

By inspecting the genre distribution in each cluster, Fig. 11, and based on the aforementioned classification, we can have a visual representation of which is the most sold genre.

```{r genreclust, echo=FALSE, fig.cap="Genre distribution in each cluster."}
# Plotting the category distribution based on 'Legend_Factors' (Genre)
# Combine cluster assignments with legend_factors
combined_data <- data.frame(Cluster = cluster_assignments, Legend_Factors = filtered_df$Genre)
# Calculate the counts of each genre
genre_counts <- table(combined_data$Legend_Factors)
genre_counts_df <- data.frame(Genre = names(genre_counts), Count = as.numeric(genre_counts))

# Reorder factor levels based on count of games
combined_data$Legend_Factors <- factor(combined_data$Legend_Factors, levels = names(sort(table(combined_data$Legend_Factors), decreasing = TRUE)))

# Plot the reordered category distribution based on counts
ggplot(data = combined_data, aes(x = Legend_Factors, fill = as.factor(Cluster))) +
  geom_bar() +
  labs(x = "Genre",
       y = "Number of Games",
       title = "Category Distribution by Clusters") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

As previously mentioned, shooter games have the highest sales, given their predominance within the second (2) cluster. Furthermore, this finding is in line with what we saw in Figure 7, where we saw that shooter games are the ones that amount to the highest sales, with some cases being predominantly sold in Japan. It is interesting to see how heterogeneous the three defined clusters are, although the sales trends are clearly visible in the results.

# References

```{=tex}
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\vspace*{-0.2in}
```
\noindent
